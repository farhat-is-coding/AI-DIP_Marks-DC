{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b750575e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82a565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\__Sandbox\\python\\university\\dip\\Untitled Folder\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972d03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72da99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ae0012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\__Sandbox\\python\\university\\dip\\Untitled Folder\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-5-12 Python-3.9.13 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the YOLOv5 model\n",
    "print(os.getcwd())\n",
    "model_name='C:/__Sandbox/python/university/dip/Untitled Folder/best.pt'\n",
    "model = torch.hub.load(os.getcwd(), 'custom', source='local', path = model_name, force_reload = True)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0c224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input image\n",
    "img_name = \"103.jpg\" # will use this below\n",
    "\n",
    "img_path = f'C:/__Sandbox/python/university/dip/Untitled Folder/{img_name}'\n",
    "img = Image.open(img_path) \n",
    "\n",
    "\n",
    "results = model(img) # batch of images\n",
    "\n",
    "# Results\n",
    "# results.print()  \n",
    "# results.save()  # or .show()\n",
    "\n",
    "# cv2.imshow('Image with bounding box', img_resized)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a4e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1 image to \u001b[1mruns\\detect\\exp3\u001b[0m\n",
      "Saved results to runs\\detect\\exp3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crops = results.crop(save=True)  # cropped detections dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33ed08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exp', 'exp2', 'exp3']\n",
      "exp3\n",
      "runs/detect/exp3\n"
     ]
    }
   ],
   "source": [
    "# basepath = os.path.dirname(__file__)\n",
    "# filepath = os.path.join(basepath,'uploads',f.filename)\n",
    "\n",
    "\n",
    "folder_path = 'runs/detect'\n",
    "subfolders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]   \n",
    "print(subfolders)\n",
    "latest_subfolder = max(subfolders, key=lambda x: os.path.getctime(os.path.join(folder_path, x)))    \n",
    "print(latest_subfolder)\n",
    "image_path = folder_path+'/'+latest_subfolder \n",
    "print(image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71030601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/detect/exp3/crops\n",
      "['marks_box', 'roll_no', 'subject_name']\n",
      "runs/detect/exp3/crops/marks_box/103.jpg\n",
      "runs/detect/exp3/crops/roll_no/103.jpg\n",
      "runs/detect/exp3/crops/subject_name/103.jpg\n"
     ]
    }
   ],
   "source": [
    "crop_images_path = image_path+'/crops' \n",
    "print(crop_images_path)\n",
    "\n",
    "crop_subfolders = [f for f in os.listdir(crop_images_path) if os.path.isdir(os.path.join(crop_images_path, f))]   \n",
    "\n",
    "print(crop_subfolders)\n",
    "# marks_box\n",
    "marks_box_path = f\"{crop_images_path}/{crop_subfolders[0]}/{img_name}\"\n",
    "roll_no_box_path = f\"{crop_images_path}/{crop_subfolders[1]}/{img_name}\"\n",
    "subject_name_path = f\"{crop_images_path}/{crop_subfolders[2]}/{img_name}\"\n",
    "\n",
    "print(marks_box_path)\n",
    "print(roll_no_box_path)\n",
    "print(subject_name_path)\n",
    "\n",
    "\n",
    "# the above paths have them images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7c1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_no_img = cv2.imread(roll_no_box_path)\n",
    "subject_name_img = cv2.imread(subject_name_path)\n",
    "marks_box_img = cv2.imread(marks_box_path)\n",
    "\n",
    "cv2.imshow('hi', roll_no_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('hi', subject_name_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('hi', marks_box_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a74837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def 30 box function: detects boxes from marks_box_img\n",
    "#     # Convert the image to grayscale\n",
    "#     marks_strip_image = cv2.cvtColor(marks_strip_image, cv2.COLOR_BGR2GRAY)\n",
    "#     # Thresholding the image\n",
    "#     (thresh, marks_strip_image) = cv2.threshold(marks_strip_image, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "#     # Invert the image\n",
    "#     marks_strip_image = 255-marks_strip_image \n",
    "#     cv2.imwrite(\"Image_bin.jpg\",marks_strip_image)\n",
    "\n",
    "\n",
    "#     # Defining a kernel length\n",
    "#     kernel_length = np.array(marks_strip_image).shape[1]//80\n",
    "\n",
    "#     # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "#     verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "#     # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "#     hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "#     # A kernel of (3 X 3) ones.\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "\n",
    "#     # Morphological operation to detect vertical lines from an image\n",
    "#     img_temp1 = cv2.erode(marks_strip_image, verticle_kernel, iterations=3)\n",
    "#     verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "#     cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "#     # Morphological operation to detect horizontal lines from an image\n",
    "#     img_temp2 = cv2.erode(marks_strip_image, hori_kernel, iterations=3)\n",
    "#     horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "#     cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "\n",
    "#     # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "#     alpha = 0.5\n",
    "#     beta = 1.0 - alpha\n",
    "#     # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "#     img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "#     img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "#     (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "#     cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "\n",
    "#     contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     idx = 0\n",
    "#     for c in reversed(contours):\n",
    "#             # Returns the location and width,height for every contour\n",
    "#             x, y, w, h = cv2.boundingRect(c)\n",
    "#             if (w < 80 and h < 80):\n",
    "#                 idx += 1\n",
    "#                 new_img = img[y:y+h, x:x+w]\n",
    "#                 cv2.imwrite(\"result\"+str(idx) + '.png', new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def OCR applier function:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
