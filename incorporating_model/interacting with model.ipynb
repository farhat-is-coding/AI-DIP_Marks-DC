{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b750575e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82a565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\University\\Semester 6 - Spring 2023\\Digital Image Processing\\LabWork\\dip_project\\AI-DIP_Marks-DC\\incorporating model\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972d03c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython>=3.1.30 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 5)) (3.1.31)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 6)) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 7)) (1.21.5)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 9)) (9.2.0)\n",
      "Requirement already satisfied: psutil in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 10)) (5.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 12)) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 13)) (1.9.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 15)) (2.0.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 16)) (0.15.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 17)) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 26)) (1.4.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 27)) (0.11.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from -r requirements.txt (line 41)) (67.7.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.9.14)\n",
      "Requirement already satisfied: filelock in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (2.8.4)\n",
      "Requirement already satisfied: colorama in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 17)) (0.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 26)) (2022.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\installedsoftwares\\anaconda\\lib\\site-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.2.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\installedsoftwares\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\installedsoftwares\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\installedsoftwares\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\installedsoftwares\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\installedsoftwares\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\installedsoftwares\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72da99a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ae0012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\University\\Semester 6 - Spring 2023\\Digital Image Processing\\LabWork\\dip_project\\AI-DIP_Marks-DC\\incorporating model\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-5-13 Python-3.9.13 torch-2.0.0+cpu CPU\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "[Errno 13] Permission denied: 'e:\\\\University\\\\Semester 6 - Spring 2023\\\\Digital Image Processing\\\\LabWork\\\\dip_project\\\\AI-DIP_Marks-DC\\\\incorporating model'. Cache may be out of date, try `force_reload=True` or see https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\University\\Semester 6 - Spring 2023\\Digital Image Processing\\LabWork\\dip_project\\AI-DIP_Marks-DC\\incorporating model\\yolov5\\hubconf.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDetectMultiBackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoshape\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# detection model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\University\\Semester 6 - Spring 2023\\Digital Image Processing\\LabWork\\dip_project\\AI-DIP_Marks-DC\\incorporating model\\yolov5\\models\\common.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, weights, device, dnn, data, fp16, fuse)\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'ERROR: {w} is not a supported format'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: ERROR: e:\\University\\Semester 6 - Spring 2023\\Digital Image Processing\\LabWork\\dip_project\\AI-DIP_Marks-DC\\incorporating model is not a supported format",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32me:\\University\\Semester 6 - Spring 2023\\Digital Image Processing\\LabWork\\dip_project\\AI-DIP_Marks-DC\\incorporating model\\yolov5\\hubconf.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# arbitrary model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\University\\Semester 6 - Spring 2023\\Digital Image Processing\\LabWork\\dip_project\\AI-DIP_Marks-DC\\incorporating model\\yolov5\\models\\experimental.py\u001b[0m in \u001b[0;36mattempt_load\u001b[1;34m(weights, device, inplace, fuse)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattempt_download\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mckpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ema'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# FP32 model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\InstalledSoftwares\\anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\InstalledSoftwares\\anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\InstalledSoftwares\\anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'e:\\\\University\\\\Semester 6 - Spring 2023\\\\Digital Image Processing\\\\LabWork\\\\dip_project\\\\AI-DIP_Marks-DC\\\\incorporating model'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4940\\4257076127.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mparent_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'custom'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'local'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparent_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_reload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\InstalledSoftwares\\anaconda\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m                                            verbose=verbose, skip_validation=skip_validation)\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\InstalledSoftwares\\anaconda\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[1;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mentry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\University\\Semester 6 - Spring 2023\\Digital Image Processing\\LabWork\\dip_project\\AI-DIP_Marks-DC\\incorporating model\\yolov5\\hubconf.py\u001b[0m in \u001b[0;36mcustom\u001b[1;34m(path, autoshape, _verbose, device)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcustom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'path/to/model.pt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_verbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m# YOLOv5 custom or local model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\University\\Semester 6 - Spring 2023\\Digital Image Processing\\LabWork\\dip_project\\AI-DIP_Marks-DC\\incorporating model\\yolov5\\hubconf.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(name, pretrained, channels, classes, autoshape, verbose, device)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mhelp_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{e}. Cache may be out of date, try `force_reload=True` or see {help_url} for help.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: [Errno 13] Permission denied: 'e:\\\\University\\\\Semester 6 - Spring 2023\\\\Digital Image Processing\\\\LabWork\\\\dip_project\\\\AI-DIP_Marks-DC\\\\incorporating model'. Cache may be out of date, try `force_reload=True` or see https://docs.ultralytics.com/yolov5/tutorials/pytorch_hub_model_loading for help."
     ]
    }
   ],
   "source": [
    "# Load the YOLOv5 model\n",
    "print(os.getcwd()) # gets the current working directory\n",
    "\n",
    "# # model_name='C:/__Sandbox/python/university/dip/Untitled Folder/best.pt'\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "model = torch.hub.load(os.getcwd(), 'custom', source='local', path = parent_dir, force_reload = True)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0c224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input image\n",
    "img_name = \"103.jpg\" # will use this below\n",
    "\n",
    "img_path = f'C:/__Sandbox/python/university/dip/Untitled Folder/{img_name}'\n",
    "img = Image.open(img_path) \n",
    "\n",
    "\n",
    "results = model(img) # batch of images\n",
    "\n",
    "# Results\n",
    "# results.print()  \n",
    "# results.save()  # or .show()\n",
    "\n",
    "# cv2.imshow('Image with bounding box', img_resized)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a4e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1 image to \u001b[1mruns\\detect\\exp3\u001b[0m\n",
      "Saved results to runs\\detect\\exp3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crops = results.crop(save=True)  # cropped detections dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33ed08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exp', 'exp2', 'exp3']\n",
      "exp3\n",
      "runs/detect/exp3\n"
     ]
    }
   ],
   "source": [
    "# basepath = os.path.dirname(__file__)\n",
    "# filepath = os.path.join(basepath,'uploads',f.filename)\n",
    "\n",
    "\n",
    "folder_path = 'runs/detect'\n",
    "subfolders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]   \n",
    "print(subfolders)\n",
    "latest_subfolder = max(subfolders, key=lambda x: os.path.getctime(os.path.join(folder_path, x)))    \n",
    "print(latest_subfolder)\n",
    "image_path = folder_path+'/'+latest_subfolder \n",
    "print(image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71030601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs/detect/exp3/crops\n",
      "['marks_box', 'roll_no', 'subject_name']\n",
      "runs/detect/exp3/crops/marks_box/103.jpg\n",
      "runs/detect/exp3/crops/roll_no/103.jpg\n",
      "runs/detect/exp3/crops/subject_name/103.jpg\n"
     ]
    }
   ],
   "source": [
    "crop_images_path = image_path+'/crops' \n",
    "print(crop_images_path)\n",
    "\n",
    "crop_subfolders = [f for f in os.listdir(crop_images_path) if os.path.isdir(os.path.join(crop_images_path, f))]   \n",
    "\n",
    "print(crop_subfolders)\n",
    "# marks_box\n",
    "marks_box_path = f\"{crop_images_path}/{crop_subfolders[0]}/{img_name}\"\n",
    "roll_no_box_path = f\"{crop_images_path}/{crop_subfolders[1]}/{img_name}\"\n",
    "subject_name_path = f\"{crop_images_path}/{crop_subfolders[2]}/{img_name}\"\n",
    "\n",
    "print(marks_box_path)\n",
    "print(roll_no_box_path)\n",
    "print(subject_name_path)\n",
    "\n",
    "\n",
    "# the above paths have them images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7c1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_no_img = cv2.imread(roll_no_box_path)\n",
    "subject_name_img = cv2.imread(subject_name_path)\n",
    "marks_box_img = cv2.imread(marks_box_path)\n",
    "\n",
    "cv2.imshow('hi', roll_no_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('hi', subject_name_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('hi', marks_box_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a74837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def 30 box function: detects boxes from marks_box_img\n",
    "#     # Convert the image to grayscale\n",
    "#     marks_strip_image = cv2.cvtColor(marks_strip_image, cv2.COLOR_BGR2GRAY)\n",
    "#     # Thresholding the image\n",
    "#     (thresh, marks_strip_image) = cv2.threshold(marks_strip_image, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "#     # Invert the image\n",
    "#     marks_strip_image = 255-marks_strip_image \n",
    "#     cv2.imwrite(\"Image_bin.jpg\",marks_strip_image)\n",
    "\n",
    "\n",
    "#     # Defining a kernel length\n",
    "#     kernel_length = np.array(marks_strip_image).shape[1]//80\n",
    "\n",
    "#     # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "#     verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "#     # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "#     hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "#     # A kernel of (3 X 3) ones.\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "\n",
    "#     # Morphological operation to detect vertical lines from an image\n",
    "#     img_temp1 = cv2.erode(marks_strip_image, verticle_kernel, iterations=3)\n",
    "#     verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "#     cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "#     # Morphological operation to detect horizontal lines from an image\n",
    "#     img_temp2 = cv2.erode(marks_strip_image, hori_kernel, iterations=3)\n",
    "#     horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "#     cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "\n",
    "#     # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "#     alpha = 0.5\n",
    "#     beta = 1.0 - alpha\n",
    "#     # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "#     img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "#     img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "#     (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "#     cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "\n",
    "#     contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     idx = 0\n",
    "#     for c in reversed(contours):\n",
    "#             # Returns the location and width,height for every contour\n",
    "#             x, y, w, h = cv2.boundingRect(c)\n",
    "#             if (w < 80 and h < 80):\n",
    "#                 idx += 1\n",
    "#                 new_img = img[y:y+h, x:x+w]\n",
    "#                 cv2.imwrite(\"result\"+str(idx) + '.png', new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def OCR applier function:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
